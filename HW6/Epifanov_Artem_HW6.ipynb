{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xrvOD02o3HvH"
      },
      "source": [
        "# Домашнее задание 6: классификация текстов"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sxwj_Iie3HvJ"
      },
      "source": [
        "В этом домашнем задании вам предстоит построить классификатор текстов!\n",
        "\n",
        "Данные мы будем использовать из Kaggle соревнования: https://www.kaggle.com/competitions/nlp-getting-started/data \n",
        "\n",
        "\n",
        "Оттуда надо скачать файл train.csv. На обучающую и тестовую выборки его поделим кодом ниже, менять его не надо!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qQVgqLg93HvJ"
      },
      "source": [
        "Мы будем работать с датасетом постов из твиттера. Нам предстоит решать задачу бинарной классификации - определять содержатся ли в твитте информация о настоящей катастрофе/инциденте или нет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TcjEYh7R3HvK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import  List\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from string import punctuation\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mjwffGiB3HvK"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v0uUoFTN3HvK",
        "outputId": "0d37d677-a00d-449c-8f86-6f85dce2ef4a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f49NdWY23HvL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.3, random_state=42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YlLemInT3HvL"
      },
      "source": [
        "## Задание 1 (0.5 балла)\n",
        "\n",
        "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их пустой строкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "96aJxmkV4105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пропуски в train:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "id             0\n",
              "keyword       44\n",
              "location    1760\n",
              "text           0\n",
              "target         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Пропуски в train:')\n",
        "display(train.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пропуски в test:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "id            0\n",
              "keyword      17\n",
              "location    773\n",
              "text          0\n",
              "target        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Пропуски в test:')\n",
        "display(test.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Пропуски есть и там, и там, заполним их:\n",
        "train = train.fillna('')\n",
        "test = test.fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пропуски в train:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "id          0\n",
              "keyword     0\n",
              "location    0\n",
              "text        0\n",
              "target      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Пропуски в train:')\n",
        "display(train.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пропуски в test:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "id          0\n",
              "keyword     0\n",
              "location    0\n",
              "text        0\n",
              "target      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Пропуски в test:')\n",
        "display(test.isna().sum())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A8CPBUal3HvL"
      },
      "source": [
        "## Задание 2 (1 балл)\n",
        "Давайте немного посмотрим на наши данные. Визуализируйте (где явно просят) или выведете информацию о следующем:\n",
        "\n",
        "1. Какое распределение классов в обучающей выборке?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WvJ_EU9o5BGm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target\n",
              "0    3024\n",
              "1    2305\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(train.value_counts('target'))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Классы немного не сбалансированны"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f08KScbP5q2y"
      },
      "source": [
        "2. Посмотрите на колонку \"keyword\" - возьмите 10 наиболее встречающихся значений, постройте ступенчатую диаграмму распределения классов в зависимости от значения keyword, сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSCb0htu5w_Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['damage',\n",
              " 'siren',\n",
              " 'wreckage',\n",
              " 'fatalities',\n",
              " 'deluge',\n",
              " 'nuclear%20reactor',\n",
              " 'derail',\n",
              " 'emergency',\n",
              " 'fatality',\n",
              " 'fear']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Беру отрезок [1; 11), так как в нулевом индексе там пустые слова\n",
        "popular_keywords = list(train.value_counts('keyword', sort=True)[1:11].index)\n",
        "display(popular_keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "r9wSwm4L9REm",
        "outputId": "3c6827d4-d35f-47ac-c756-6ab4740ed0b9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "sns.histplot(train[train['keyword'].isin(popular_keywords)],\n",
        "             x='keyword', hue='target', multiple='layer', alpha=0.4, edgecolor=None)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l4al3g9E-P09"
      },
      "source": [
        "**Выводы**:\n",
        "* Число твитов о ненастоящей катастрофе больше (оно и ожидаемо, нужно же привлекать к себе внимание на инфоповодах)\n",
        "* Что примечательно, слово wreckage (крушение) появляется только в твитах о реальных катастрофах. Возможно сложно подделать новость о крушении чего-либо (например самолёта), если ты это не можешь прикрепить никакими кадрами. Ну то есть когда пишешь о крушении, то вероятно читатель ожидает получение фотографий этого крушения. Но это сугубо моё мнение\n",
        "* Так же странно, что слово derail встречается поровну и в нормальных твитах, и фейковых"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c006nNBP3HvM"
      },
      "source": [
        "## Задание 3 (0.5 балла) \n",
        "\n",
        "В этом задании предлагается объединить все три текстовых столбца в один (просто сконкатенировать cтроки) и убрать столбец с индексом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GdF9gFmL-c0r",
        "outputId": "ebe008b7-4d0e-4bc2-89f3-60a575c1b1fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6590</th>\n",
              "      <td>9436</td>\n",
              "      <td>survivors</td>\n",
              "      <td>Marietta, GA</td>\n",
              "      <td>Stemming from my #Cubs talk- the team rosters ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7122</th>\n",
              "      <td>10203</td>\n",
              "      <td>violent%20storm</td>\n",
              "      <td></td>\n",
              "      <td>If you were the NWS wth a rotating storm w/ a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2769</th>\n",
              "      <td>3980</td>\n",
              "      <td>devastation</td>\n",
              "      <td>Atlanta g.a.</td>\n",
              "      <td>http://t.co/Gxgm1T3W0J From Devastation to Ela...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id          keyword      location  \\\n",
              "6590   9436        survivors  Marietta, GA   \n",
              "7122  10203  violent%20storm                 \n",
              "2769   3980      devastation  Atlanta g.a.   \n",
              "\n",
              "                                                   text  target  \n",
              "6590  Stemming from my #Cubs talk- the team rosters ...       1  \n",
              "7122  If you were the NWS wth a rotating storm w/ a ...       1  \n",
              "2769  http://t.co/Gxgm1T3W0J From Devastation to Ela...       0  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.loc[[6590, 7122, 2769]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lwwJKX_l-eoh"
      },
      "outputs": [],
      "source": [
        "train_new = train.drop('id', axis=1)\n",
        "test_new = test.drop('id', axis=1)\n",
        "\n",
        "train_new['concated'] = train_new.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "test_new['concated'] = test_new.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "\n",
        "train_new = train_new.drop(['keyword', 'location', 'text'], axis=1)\n",
        "test_new = test_new.drop(['keyword', 'location', 'text'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "jk7P70XX_CpT",
        "outputId": "5cf01b29-8ada-46d7-f7ee-74e7aed37996"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>concated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6590</th>\n",
              "      <td>1</td>\n",
              "      <td>survivors Marietta, GA Stemming from my #Cubs ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7122</th>\n",
              "      <td>1</td>\n",
              "      <td>violent%20storm  If you were the NWS wth a rot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2769</th>\n",
              "      <td>0</td>\n",
              "      <td>devastation Atlanta g.a. http://t.co/Gxgm1T3W0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      target                                           concated\n",
              "6590       1  survivors Marietta, GA Stemming from my #Cubs ...\n",
              "7122       1  violent%20storm  If you were the NWS wth a rot...\n",
              "2769       0  devastation Atlanta g.a. http://t.co/Gxgm1T3W0..."
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_new.loc[[6590, 7122, 2769]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ViXdGTxP3HvM"
      },
      "source": [
        "## Задание 4 (0.5 балла)\n",
        "\n",
        "Далее мы будем пока работать только с train частью.\n",
        "\n",
        "1. Предобработайте данные (train часть) с помощью CountVectorizer.\n",
        "2. Какого размера получилась матрица?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oB1MTqUVAbPA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размерность матрицы: (5329, 18455)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cnt_vec = CountVectorizer()\n",
        "train_vec = cnt_vec.fit_transform(train_new['concated'])\n",
        "print('Размерность матрицы:', train_vec.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A4waLlnC3HvM"
      },
      "source": [
        "## Задание 5 (1 балл)\n",
        "\n",
        "В предыдущем пункте у вас должна была получиться достаточно большая матрица.\n",
        "Если вы взгляните на текст, то увидете, что там есть множество специальных символов, ссылок и прочего мусора.\n",
        "\n",
        "Давайте также посмотрим на словарь, который получился в результате построения CountVectorizer, его можно найти в поле vocabulary_ инстанса этого класса. Давайте напишем функцию, которая печает ответы на следующие вопросы:\n",
        "\n",
        "1. Найдите в этом словаре все слова, которые содержат цифры. Сколько таких слов нашлось?\n",
        "\n",
        "2. Найдите все слова, которые содержат символы пунктуации. Сколько таких слов нашлось? \n",
        "\n",
        "3. Сколько хэштегов (токен начинается на #) и упоминаний (токен начинается на @) осталось в словаре?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7PhQSWqcHhU8"
      },
      "outputs": [],
      "source": [
        "def contains_digit(s: str) -> bool:\n",
        "    # Проверка, содержит ли слово цифры\n",
        "    return bool(re.search(r'\\d', s))\n",
        "\n",
        "def contains_punctuation(s: str) -> bool:\n",
        "    # Проверка, содержит ли слово пунктуацию\n",
        "    return any(char in punctuation for char in s)\n",
        "\n",
        "def is_hashtag(s: str) -> bool:\n",
        "    # Проверка, является ли слово хэштегом\n",
        "    return s.startswith('#')\n",
        "\n",
        "def is_mention(s: str) -> bool:\n",
        "    # Проверка, является ли слово упоминанием\n",
        "    return s.startswith('@')\n",
        "\n",
        "\n",
        "def investigate_vocabulary(vocabulary):\n",
        "    with_digits = 0\n",
        "    with_punctuation = 0\n",
        "    with_hashtag = 0\n",
        "    with_mention = 0\n",
        "    for word in vocabulary.keys():\n",
        "        if contains_digit(word):\n",
        "            with_digits += 1\n",
        "        if contains_punctuation(word):\n",
        "            with_punctuation += 1\n",
        "        if is_hashtag(word):\n",
        "            with_hashtag += 1\n",
        "        if is_mention(word):\n",
        "            with_mention += 1\n",
        "\n",
        "    print('With digit:      ', with_digits)\n",
        "    print('With punctuation:', with_punctuation)\n",
        "    print('Hashtags:        ', with_hashtag)\n",
        "    print('Mentions:        ', with_mention)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8hL5ZcQIdp6",
        "outputId": "c8b50455-38f2-455d-c9f6-96b03a7e09ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With digit:       2\n",
            "With punctuation: 7\n",
            "Hashtags:         1\n",
            "Mentions:         3\n"
          ]
        }
      ],
      "source": [
        "dummy_vocab = {'th1nk' : 0,\n",
        "               'think333' : 1,\n",
        "               'think.' : 2,\n",
        "               'th!nk' : 3,\n",
        "               'th...nk' : 4,\n",
        "               '#think' : 5,\n",
        "               '@think' : 6,\n",
        "               '@thinking':7,\n",
        "               '@nothink' : 8,\n",
        "               'think' : 9}\n",
        "investigate_vocabulary(dummy_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VpW8R_SuKR_l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With digit:       3812\n",
            "With punctuation: 315\n",
            "Hashtags:         0\n",
            "Mentions:         0\n"
          ]
        }
      ],
      "source": [
        "investigate_vocabulary(cnt_vec.vocabulary_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bfNLaxX93HvM"
      },
      "source": [
        "## Задание 6 (0.5 балла)\n",
        "\n",
        "Вспомним, что на семинаре по текстам мы узнали, что в nltk есть специальный токенизатор для текстов - TweetTokenizer. Попробуем применить CountVectorizer с этим токенизатором. Ответьте на все вопросы из предыдущего пункта для TweetTokenizer и сравните результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xnlRoXUS3HvM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class TweetTokenizer in module nltk.tokenize.casual:\n",
            "\n",
            "class TweetTokenizer(nltk.tokenize.api.TokenizerI)\n",
            " |  TweetTokenizer(preserve_case=True, reduce_len=False, strip_handles=False, match_phone_numbers=True)\n",
            " |  \n",
            " |  Tokenizer for tweets.\n",
            " |  \n",
            " |      >>> from nltk.tokenize import TweetTokenizer\n",
            " |      >>> tknzr = TweetTokenizer()\n",
            " |      >>> s0 = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
            " |      >>> tknzr.tokenize(s0) # doctest: +NORMALIZE_WHITESPACE\n",
            " |      ['This', 'is', 'a', 'cooool', '#dummysmiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->',\n",
            " |       '<--']\n",
            " |  \n",
            " |  Examples using `strip_handles` and `reduce_len parameters`:\n",
            " |  \n",
            " |      >>> tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
            " |      >>> s1 = '@remy: This is waaaaayyyy too much for you!!!!!!'\n",
            " |      >>> tknzr.tokenize(s1)\n",
            " |      [':', 'This', 'is', 'waaayyy', 'too', 'much', 'for', 'you', '!', '!', '!']\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      TweetTokenizer\n",
            " |      nltk.tokenize.api.TokenizerI\n",
            " |      abc.ABC\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, preserve_case=True, reduce_len=False, strip_handles=False, match_phone_numbers=True)\n",
            " |      Create a `TweetTokenizer` instance with settings for use in the `tokenize` method.\n",
            " |      \n",
            " |      :param preserve_case: Flag indicating whether to preserve the casing (capitalisation)\n",
            " |          of text used in the `tokenize` method. Defaults to True.\n",
            " |      :type preserve_case: bool\n",
            " |      :param reduce_len: Flag indicating whether to replace repeated character sequences\n",
            " |          of length 3 or greater with sequences of length 3. Defaults to False.\n",
            " |      :type reduce_len: bool\n",
            " |      :param strip_handles: Flag indicating whether to remove Twitter handles of text used\n",
            " |          in the `tokenize` method. Defaults to False.\n",
            " |      :type strip_handles: bool\n",
            " |      :param match_phone_numbers: Flag indicating whether the `tokenize` method should look\n",
            " |          for phone numbers. Defaults to True.\n",
            " |      :type match_phone_numbers: bool\n",
            " |  \n",
            " |  tokenize(self, text: str) -> List[str]\n",
            " |      Tokenize the input text.\n",
            " |      \n",
            " |      :param text: str\n",
            " |      :rtype: list(str)\n",
            " |      :return: a tokenized list of strings; joining this list returns        the original string if `preserve_case=False`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  PHONE_WORD_RE\n",
            " |      Secondary core TweetTokenizer regex\n",
            " |  \n",
            " |  WORD_RE\n",
            " |      Core TweetTokenizer regex\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from nltk.tokenize.api.TokenizerI:\n",
            " |  \n",
            " |  span_tokenize(self, s: str) -> Iterator[Tuple[int, int]]\n",
            " |      Identify the tokens using integer offsets ``(start_i, end_i)``,\n",
            " |      where ``s[start_i:end_i]`` is the corresponding token.\n",
            " |      \n",
            " |      :rtype: Iterator[Tuple[int, int]]\n",
            " |  \n",
            " |  span_tokenize_sents(self, strings: List[str]) -> Iterator[List[Tuple[int, int]]]\n",
            " |      Apply ``self.span_tokenize()`` to each element of ``strings``.  I.e.:\n",
            " |      \n",
            " |          return [self.span_tokenize(s) for s in strings]\n",
            " |      \n",
            " |      :yield: List[Tuple[int, int]]\n",
            " |  \n",
            " |  tokenize_sents(self, strings: List[str]) -> List[List[str]]\n",
            " |      Apply ``self.tokenize()`` to each element of ``strings``.  I.e.:\n",
            " |      \n",
            " |          return [self.tokenize(s) for s in strings]\n",
            " |      \n",
            " |      :rtype: List[List[str]]\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from nltk.tokenize.api.TokenizerI:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "help(TweetTokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8lPMIf6UKccT"
      },
      "outputs": [],
      "source": [
        "twt_tkn = TweetTokenizer()\n",
        "cnt_vec_twt = CountVectorizer(tokenizer=twt_tkn.tokenize)\n",
        "train_vec = cnt_vec_twt.fit_transform(train_new['concated'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7oR5kNKVLLpm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With digit:       3939\n",
            "With punctuation: 7338\n",
            "Hashtags:         1470\n",
            "Mentions:         1679\n"
          ]
        }
      ],
      "source": [
        "investigate_vocabulary(cnt_vec_twt.vocabulary_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wetr80-ILULV"
      },
      "source": [
        "**Сравнение:** \n",
        "* Токенайзер стал пропускать гораздо больше слов с символами пунктуации в самом слове\n",
        "* Также токенайзер не разбивает слова при встрече специальных символов в твиттере (хэштега и упоминания)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6_k_-i1x3HvM"
      },
      "source": [
        "## Задание 7 (2 балла)\n",
        "\n",
        "В scikit-learn мы можем оценивать процесс подсчета матрицы через CountVectorizer. У CountVectorizer, как и у других наследников \\_VectorizerMixin, есть аргумент tokenizer и preprocessor. preprocessor применится в самом начале к каждой строке вашего датасета, tokenizer же должен принять строку и вернуть токены.\n",
        "Давайте напишем кастомный токенайзер, которые сделает все, что нам нужно: \n",
        "\n",
        "0. Приведет все буквы к нижнему регистру\n",
        "1. Разобьет текст на токены с помощью TweetTokenizer из пакета nltk\n",
        "2. Удалит все токены содержащие не латинские буквы, кроме смайликов (будем считать ими токены содержащие только пунктуацию и, как минимум, одну скобочку) и хэштегов, которые после начальной # содержат только латинские буквы.\n",
        "3. Удалит все токены, которые перечислены в nltk.corpus.stopwords.words('english')\n",
        "4. Проведет стемминг с помощью SnowballStemmer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from string import ascii_letters\n",
        "import nltk\n",
        "# nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qhwmi7DEMD25"
      },
      "outputs": [],
      "source": [
        "brackets = '{([])}'\n",
        "smiling_symbols = punctuation + brackets\n",
        "stemm = SnowballStemmer('english')\n",
        "tweet_tkn = TweetTokenizer()\n",
        "\n",
        "def contains_only_latin_letters(s: str) -> bool:\n",
        "    # Проверка, содержит ли слово только латинские буквы\n",
        "    return all(char in ascii_letters for char in s)\n",
        "\n",
        "\n",
        "def is_emoji(s: str) -> bool:\n",
        "    # Проверка, является ли слово смайликом\n",
        "    return all(char in smiling_symbols for char in s) and any(char in brackets for char in s)\n",
        "\n",
        "\n",
        "def is_hashtag(s: str) -> bool:\n",
        "    # Проверка, является ли слово хэштегом\n",
        "    return s.startswith('#') and s.count('#') == 1\n",
        "\n",
        "\n",
        "def custom_tokenizer(s: str) -> List[str]:\n",
        "    s = s.lower()\n",
        "    bad_tokens = tweet_tkn.tokenize(s)\n",
        "    result_tokens = []\n",
        "    for token in bad_tokens:\n",
        "        if (is_emoji(token) or is_hashtag(token) or contains_only_latin_letters(token)) and token not in nltk.corpus.stopwords.words('english'):\n",
        "            result_tokens.append(stemm.stem(token))\n",
        "    return result_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYzPZzf8O6vj",
        "outputId": "b1107f8a-eef7-49f7-8ed3-910be791d645"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['love', 'paint', ':-)', '#art']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_tokenizer('She LOVES painting :-) #art')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2S_-ThAf5It4"
      },
      "source": [
        "Продемонстрируйте работу вашей функции на первых десяти текстах в обучающей выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "A1fh3_itPz7D"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1186    [bridg, ash, australia, collaps, trent, bridg,...\n",
              "4071    [hail, carol, stream, illinoi, great, michigan...\n",
              "5461    [polic, houston, cnn, tennesse, movi, theater,...\n",
              "5787        [riot, still, riot, coupl, hour, left, class]\n",
              "7445    [wound, lake, highland, crack, path, wipe, mor...\n",
              "151     [airplan, somewher, expert, franc, begin, exam...\n",
              "915     [bloodi, isol, citi, world, perth, came, kill,...\n",
              "1305                    [burn, except, idk, realli, burn]\n",
              "2570                  [destroy, (, ask, ), destroy, hous]\n",
              "7399    [wound, maracay, nirgua, venezuela, polic, off...\n",
              "Name: concated, dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(train_new['concated'].head(10).apply(custom_tokenizer))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a5lNZ4tb3HvN"
      },
      "source": [
        "## Задание 8 (1 балл)\n",
        "\n",
        "1. Примените CountVectorizer с реализованным выше токенизатором к обучающим и тестовым выборкам.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LDqixz7QQEbn"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "train_vec = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec = vectorizer.transform(test_new['concated'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YcetwuEi5ds9"
      },
      "source": [
        "2. Обучите LogisticRegression на полученных признаках.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BVj03QV2QbWl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec.toarray(), train_new['target'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ch6uz2P5e-T"
      },
      "source": [
        "3. Посчитайте метрику f1-score на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osyC0pdT3cSD",
        "outputId": "cd957d5f-5118-4b7f-d7ba-01bb5a524086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83      1318\n",
            "           1       0.78      0.72      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.752017213555675\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = lr.predict(test_vec.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aFIEYOMZ3HvN"
      },
      "source": [
        "## Задание 9 (1 балл)\n",
        "\n",
        "1. Повторите 8 задание, но с tf-idf векторизатором. Как изменилось качество?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDqs61hl3ve3",
        "outputId": "fdd72125-dfde-4183-d614-3b0bc9002ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83      1318\n",
            "           1       0.80      0.69      0.74       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.78      0.79      2284\n",
            "weighted avg       0.80      0.80      0.79      2284\n",
            "\n",
            "\n",
            "F1 score: 0.7419354838709677\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1\n",
        "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
        "train_vec_tf = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec_tf = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec_tf.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec_tf.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SXaNclTZSFjO"
      },
      "source": [
        "1. **Ответ:** качество практически не изменилось"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CPtk0lCA5POY"
      },
      "source": [
        "2. Мы можем еще сильнее уменьшить размер нашей матрицы, если отбросим значения df близкие к единице. Скорее всего такие слова не несут много информации о категории, так как встречаются достаточно часто. Ограничьте максимальный df в параметрах TfIdfVectorizer, поставьте верхнюю границу равную 0.9. Как изменился размер матрицы, как изменилось качество?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU-MRXyRSHLm",
        "outputId": "6b5353a8-5f3b-4220-fcd4-64eecfe20054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83      1318\n",
            "           1       0.80      0.69      0.74       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.78      0.79      2284\n",
            "weighted avg       0.80      0.80      0.79      2284\n",
            "\n",
            "\n",
            "F1 score: 0.7419354838709677\n"
          ]
        }
      ],
      "source": [
        "# 2\n",
        "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=0.9)\n",
        "train_vec_tf = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec_tf = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec_tf.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec_tf.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "z1TkO9HeSTJ9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5329, 10610)\n",
            "(5329, 10610)\n"
          ]
        }
      ],
      "source": [
        "print(train_vec.shape)\n",
        "print(train_vec_tf.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4Two_O3rSVmh"
      },
      "source": [
        "2. **Ответ:** качество вообще не поменялось, и размер тоже => нет слов, которые так часто встречаются"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VhyjbI5X5QnG"
      },
      "source": [
        "3. Также мы можем уменьшить размер матрицы, удаляя слова со слишком маленьким df. Удалось ли добиться улучшения качества? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mNpIxv6SfKc",
        "outputId": "607ec22e-1fdb-4c29-bbc4-6447ed266349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n"
          ]
        }
      ],
      "source": [
        "# 3\n",
        "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=0.9, min_df=0.0003)\n",
        "train_vec_tf = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec_tf = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec_tf.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec_tf.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5329, 10610)\n",
            "(5329, 4538)\n"
          ]
        }
      ],
      "source": [
        "print(train_vec.shape)\n",
        "print(train_vec_tf.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "imeD8skxSqdg"
      },
      "source": [
        "3. **Ответ:** совсем немного подняли f1-меру, сократили количество слов"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1l1sx4nB3HvN"
      },
      "source": [
        "## Задание 10 (1 балл)\n",
        "\n",
        "Еще один популяпный трюк, который позволит уменьшить количество признаков называется hashing trick. Его суть в том, то мы случайно группируем признаки ииии  ..... складываем их! А потом удаляем исходные признаки. В итоге все наши признаки это просто суммы исходных. Звучит странно, но это отлично работает. Давайте проверим этот трюк в нашем сеттинге.\n",
        "Также при таком подходе вам не нужно хранить словарь token->index, что тоже иногда полезно.\n",
        "\n",
        "1. Повторите задание 8 с HashingVectorizer, укажите количество фичей равное 5000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qSoW894RXxz",
        "outputId": "720818f4-f774-4273-bb10-918ecc72ef44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82      1318\n",
            "           1       0.78      0.67      0.72       966\n",
            "\n",
            "    accuracy                           0.78      2284\n",
            "   macro avg       0.78      0.76      0.77      2284\n",
            "weighted avg       0.78      0.78      0.78      2284\n",
            "\n",
            "\n",
            "F1 score: 0.7183491355270497\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "vectorizer = HashingVectorizer(tokenizer=custom_tokenizer, n_features=5000)\n",
        "train_vec_hash = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec_hash = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec_hash.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec_hash.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1C3I4ceg6AG-"
      },
      "source": [
        "2. Какой из подходов показал самый высокий результат?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_bIfyVlOS9Lu"
      },
      "source": [
        "1. **Ответ:** hashing trick оказался так себе. Наилушим оказался с одной стороны CountVectoraizer, но в tf-idf можно сократить количество слов."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zylJ6l0R3HvN"
      },
      "source": [
        "## Задание 11 (1 балл)\n",
        "\n",
        "В этом задании нужно добиться f1 меры хотя в 0.75 на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GSTVApFeS-OY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.80      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.7455555555555555\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83      1318\n",
            "           1       0.78      0.72      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.752017213555675\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.98      0.78      1318\n",
            "           1       0.92      0.28      0.43       966\n",
            "\n",
            "    accuracy                           0.69      2284\n",
            "   macro avg       0.78      0.63      0.61      2284\n",
            "weighted avg       0.76      0.69      0.64      2284\n",
            "\n",
            "\n",
            "F1 score: 0.43443917851500785\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Пробуем n-граммы\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, ngram_range=(1, 3))\n",
        "train_vec = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))\n",
        "print('\\n\\n')\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, ngram_range=(1, 1))\n",
        "train_vec = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))\n",
        "print('\\n\\n')\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, ngram_range=(3, 3))\n",
        "train_vec = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))\n",
        "print('\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min_df=0.0001      max_df=0.1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.0002      max_df=0.09000000000000001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.00030000000000000003      max_df=0.08\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.0004      max_df=0.07\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.0005      max_df=0.060000000000000005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.0006000000000000001      max_df=0.05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.0007000000000000001      max_df=0.04000000000000001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.0008      max_df=0.03\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.0009000000000000001      max_df=0.020000000000000004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n",
            "min_df=0.001      max_df=0.010000000000000009\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.83      1318\n",
            "           1       0.81      0.69      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.745969983324069\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    max_df = 0.1\n",
        "    min_df = 0.0001\n",
        "    max_df -= i * 0.01\n",
        "    min_df += i * 0.0001\n",
        "    vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=0.9, min_df=0.0003)\n",
        "    train_vec_tf = vectorizer.fit_transform(train_new['concated'])\n",
        "    test_vec_tf = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "    lr = LogisticRegression()\n",
        "    lr.fit(train_vec_tf.toarray(), train_new['target'])\n",
        "\n",
        "    y_pred = lr.predict(test_vec_tf.toarray())\n",
        "\n",
        "    print(f'min_df={min_df}      max_df={max_df}')\n",
        "    print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "    print()\n",
        "    print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83      1318\n",
            "           1       0.78      0.72      0.75       966\n",
            "\n",
            "    accuracy                           0.80      2284\n",
            "   macro avg       0.80      0.79      0.79      2284\n",
            "weighted avg       0.80      0.80      0.80      2284\n",
            "\n",
            "\n",
            "F1 score: 0.752017213555675\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Стандартный вариант оказался самым лучшим\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "train_vec = vectorizer.fit_transform(train_new['concated'])\n",
        "test_vec = vectorizer.transform(test_new['concated'])\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec.toarray(), train_new['target'])\n",
        "\n",
        "y_pred = lr.predict(test_vec.toarray())\n",
        "\n",
        "\n",
        "print(classification_report(y_true=test_new['target'], y_pred=y_pred))\n",
        "print()\n",
        "print('F1 score:', f1_score(y_true=test_new['target'], y_pred=y_pred))\n",
        "print('\\n\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YlLemInT3HvL",
        "A8CPBUal3HvL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
